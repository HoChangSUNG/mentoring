# 19장

## **JVM**

- 자바를 실행하기 위한 가상 기계
- 자바 바이트 코드를 OS에 특화된 코드로 변환하여 실행
    - 자바 바이트 코드는 JVM에서 실행될 수 있는 OS에 독립적이다. 따라서 자바 바이트 코드를 각각의 운영체제에 맞게 기계어로 바꿔야 하는데 이 과정을 해주는 것이 JVM이다.

## **JVM 메모리 구조와 동작**

![Untitled](https://github.com/HoChangSUNG/mentoring/assets/76422685/a9b3f4c9-2d53-4609-bff3-4195539c9f9d)


### 메모리 구조

- **Class Loader**
    - 클래스 파일(자바 바이트 코드)을 동적으로 메모리(Method Area)에 로딩하는 역할을 한다
    - JVM이 동작하다가 클래스 파일을 참조하게 되면 해당 클래스 파일을 Class Loader가 동적으로 메모리(Method Area)에 로딩해준다
- **Garbage Collector**
    - heap 영역에 있는 메모리에서 더 이상 사용하지 않는 메모리를 회수해줌
- **Execution Engine**
    - Class Loader에 의해 JVM으로 로딩된  클래스 파일(바이트 코드)을 순서대로 명령어 단위로 읽어 JIT 컴파일러를 통해 기계어로 변환하고, 이를 CPU가 실행
    - JVM으로 로딩된  클래스 파일은 method Area에 존재

- **Method Area**
    - 클래스가 메모리 상에 올라가는 영역
    - JVM이 동작하고 클래스가 클래스 로더에 의해 적재된 후부터 프로그램이 종료될 때까지 저장
    - GC의 영향으로부터 자유로움
    - 클래스의 바이트 코드, 상수, 메서드, 필드 등의 정보가 저장됨(Constant Pool,static 변수 포함)

- **Heap Area**
    - 동적 메모리 저장 공간
    - new 키워드로 생성된 객체와 배열이 생성되는 영역
    - garbage collection의 대상이 됨
- **Stack Area**
    - 지역변수, 인자값, 리턴값이 저장되는 영역
    - 메소드 호출할 때마다 stack frame이 Stack Area에 저장되고 메서드 실행이 끝나면 stack에서 제거됨
    - LIFO 방식으로 stack frame을 stack area에 넣었다가 빼는 방식으로 동작
    - stack frame
        - 메소드가 호출될 때마다 생성되며, 메소드의 상태와 지역변수, 인자값, 리턴값을 저장
- **PC register**
    - Thread가 현재 실행하고 있는 부분의 주소와 명령을 저장하고 있다
    - 왜 필요한가?
        - 해당 쓰레드가 Runnable 상태에서 다른 상태로 되었다가 다시 Runnable 상태가 되었을 때 어느 부분을 실행해야 하는지를 알아야 하기 때문에
- **Native Method Stack**
    - 자바 이외의 언어(C, C++, 어셈블리 등)로 작성된 네이티브 코드를 실행할 때 사용되는 메모리 영역
    - 쓰레드가 native method 호출할 때마다 추가되고 native method 종료시 삭제
- **PermGen(Permanent Generation)**
    - non-heap 영역으로 GC 대상이 아님
    - 클래스의 메타 데이터 저장

- **Metaspace**
    - java 8 이후 JVM에서 PermGen 영역을 대체하는 메모리 영역
    - 클래스 메타 데이터 저장
    - Native 메모리 영역에 존재 → 메모리 할당과 해제는 운영 체제 수준에서 처리
    - 동적으로 메모리 크기 조정 가능(PermGen은 고정된 크기를 가져 메모리 부족 문제 발생 가능)
    - 클래스의 메모리 관리(메모리 할당과 해제)를 자동으로 처리
    - HEAP 영역이 아니기 때문에 GC의 대상이 아님
- **모든 스레드가 공유해서 사용**
    - Method Area, Heap Area, Metaspace
- **쓰레드마다 분리**
    - Stack Area, PC register, Native Method Stack

### 동작 순서

1. 자바 소스(.java)를 컴파일러를 이용해 컴파일 → class 파일(자바 바이트 코드, `.class`)이 생성되어 디스크에 저장
    - 컴파일러 : 컴파일을 하는 프로그램
    - 컴파일 : 내가 작성한 코드를 컴퓨터가 이해할 수 있도록 엮어주는 작업, class 파일이 생성되어 디스크에 저장
2.  클래스 로더가 클래스 파일 jvm에 적재(java 실행할 경우)
    - 클래스 로더가 필요한 자바 바이트 코드(클래스 파일)을 동적으로 jvm의 method area에 저장
    - 그 후 자바 바이트 코드를 `java.lang.Class` 객체로 변환하여 클래스 메타 데이터를 Metaspace에 저장
3. Execution engine이 JVM으로 로딩된  클래스 파일을 읽어서 실행
    - 클래스 파일을 읽고 JIT 컴파일러로 실행한다.

컴퓨터 프로그램을 실행하는 방식

- 인터프리트(interpret) 방식
    - 코드를 한줄씩 읽어서 기계 언어로 변환한다
    - 장점 : 목적 코드를 만들지 않고 링킹 과정도 거치지 않기 때문에 메모리 효율 좋음
    - 단점 :
        - 변환과 실행을 동시에 진행해야 하므로 실행 속도가 느림
        - 한번에 한 문장씩 읽어 프로그램을 실행해야 오류 발견 가능
- 정적(static) 컴파일 방식
    - 소스 코드를 한꺼번에 다른 목적 코드로 변환한 후, 한 번에 실행하는 프로그램
    - 장점
        - 이미 변환된 코드를 실행만 하면 되서 실행 속도가 빠름
        - 전체 코드를 변환할 때 검사하여 프로그램 실행 전에 오류 발견 가능
    - 단점 : 기계어로 번역시 목적 코드(Object code)를 만드는데 오브젝트 코드를 묶어서 하나의 실행 파일로 만드는 링킹 작업을 해서 메모리를 많이 사용

**JIT 컴파일러**

- JVM에서 바이트 코드를 기계어로 번역하는 컴파일러
- 왜 만들었나?
    - 프로그램 실행을 보다 빠르게 하기 위해
- C1 컴파일러와 C2 컴파일러로 구성
    - C1 컴파일러 : 런타임에 바이트 코드를 기계어로 변환하는 과정만을 수행
    - C2 컴파일러 : 런타임에 바이트 코드를 기계어로 변환한 다음 캐시에 저장하는 과정 수행
- 어떻게 성능을 최적화했나?
    - 원래
        - 바이트 코드로 컴파일하는 과정과 JVM에서 바이트 코드를 인터프리트 하는 과정, 두 가지를 거쳐야 해서 성능이 좋지 않음
    - **JIT 컴파일러를 이용한 성능 개선 방법**
        - 실행 시점에 인터프리터와 같이 바이트 코드를 기계어 코드로 컴파일하면서 컴파일된 기계어를 캐시에 저장한다.

          그 후  동일한 바이트 코드를 재사용할 때 컴파일하지 않고 캐시에 저장되어 있는 기계어를 사용한다.

- 장점
    - 반복적으로 수행되는 코드에 대해서는 캐시에 있는 기계어를 사용하기 때문에 빠른 성능
- 단점
    - 처음에 시작할 때는 바이트 코드를 인터프리트하는 과정(캐시에 없기 때문)을 거쳐야 해서 성능이 느림

**HotSpot 클라이언트 컴파일러**

- CPU 코어가 하나뿐인 사용자를 위해 만들어진 것
- 특징
    - 애플리케이션 시작 시간을 빠르게 함
    - 적은 메모리를 점유하도록 함


**HotSpot 서버 컴파일러**

- CPU 코어가 많은 장비에서 애플리케이션을 동작하기 위해 만들어짐
- 2개 이상의 물리적 프로세서, 2GB 이상의 물리적 메모리 조건을 만족하면 JVM이 서버 컴파일러를 선택

※ OS 에 따라 클라이언트/서버 컴파일러 중 무엇을 사용할지 정해져 있기도 함

윈도우는 기본적으로 지정해주지 않으면 클라이언트 컴파일러 사용

**※ HotSpot 컴파일러는 JIT 컴파일러의 구현체**

**weak generational hypothesis(약한 세대 가설)**

- 대부분의 객체는 금방 접근 불가능 상태(unreachable)가 된다
- 오래된 객체에서 젊은 객체로의 참조는 아주 적게 존재한다,

**GC(Garbage Collection) - [참고링크](https://d2.naver.com/helloworld/1329)**

- heap 영역의 메모리를 관리
- 사용하지 않는 객체를 찾고 객체의 메모리 할당을 해제
- weak generational hypothesis(약한 세대 가설) 가설 하에 만들어짐

  → 이 가설의 장점을 살리기 위해 heap 영역을 Young,Old 영역으로 나눔


- heap 영역
    - Young, Old, Perm 영역으로 구분
    - **Young 영역**
        - 젊은 객체들이 존재
        - 대부분의 객체가 금방 접근 불가능 상태가 되서 많은 객체들이 Young 영역에 생성되었다 사라짐
        - 2개의 Survivor 영역과 Eden 영역으로 나뉨
            - Eden 영역 : 새로 생성된 객체가 저장
            - Survivor 영역 : 1회 이상의 GC에서 살아남은 객체가 존재
    - **Old 영역**
        - 오래된 객체들이 존재(Young 영역에서 살아남은 객체)
        - Young 영역보다 크게 할당, 크기가 큰 만큼 Young영역보다 GC가 적게 일어남
    - **Perm 영역** : 클래스나 메소드 정보 저장



- minor GC(Young GC)
    - Young 영역에서 GC가 이루어지는 것
    - Eden 영역이 꽉 찼을 때 발생
    - **Young 영역의 동작 순서**
        1. Eden 영역에 객체가 생성
        2. Eden 영역이 꽉 차면 살아있는 객체만 Survivor영역으로 객체 복사, Eden 영역을 다시 채우기 시작
        3. Survivor 영역이 꽉 차면 Survivor의 살아있는 객체가 다른 Survivor 영역으로 객체 복사, Eden 영역에 살아 있는 객체들도 다른 Survivor 영역으로 객체 복사

           즉, Survivor 영역 중 하나는 무조건 비어있어야 함

    - 위 과정을 거쳐 오래 살아남은 객체들은 Old 영역으로 이동(Promotion)
- major GC(Full GC)
    - Old 영역이 꽉 찼을 때 발생

**※ reachable(살아있는) 객체란?**

- root로부터 해당 객체에 대한 유효한 참조가 있는 경우
- root는 stack 영역에 의한 참조, method 영역의 클래스 변수에 의한 참조

**HotSpot JVM에서는 보다 빠른 메모리 할당(Eden에 객체 할당)을 위한 두 가지 기술**

- bump-the-pointer
    - Eden 영역에 할당된 마지막 객체는 Eden 맨 위(top)에 존재하고 이 마지막 객체를 추적하는 것
    - 새로운 객체가 생성되면, 생성되는 객체의 크기가 Eden 영역에 넣기 적당한지 확인하고, 적당하면 Eden 영역에 넣고, 이 객체를 bump-the-pointer가 추적

      → 새로운 객체를 Eden 영역에 생성할 경우, 마지막에 생성된 객체만 점검하면 되서 빠르게 메모리 할당이 가능

- TLABs(Thread-Local Allocation Buffers)
    - 멀티 쓰레드 환경에서는 Eden 영역에 객체를 저장하려면 Thread-safe 해야 해서 락이 발생하고 락 경합(lock-contention)이 발생해 성능 저하되는 문제를 해결
    - 각각의 스레드마다 Eden 영역의 작은 덩어리를 가질 수 있게 하고 이 덩어리에만 접근할 수 있는데 이것이 TLABs이다
    - 각 스레드가 가지는 TLABs에만 접근할 수 있어 bump-the-pointer 기술을 사용해서 락 없이 메모리 할당이 가능


**왜 Young 영역의 두개의 Survivor중 하나의 Survivor는 비어있어야 하는가?**

- survivor 영역을 검사하면서 죽은 객체를 제거하는데 이 과정에서 죽은 객체가 제거된 부분에 구멍이 생기게 된다. 이로 인해 suvivor 영역의 공간이 남아있지만 저장하지 못하는 fragmentation(단편화)문제가 발생할 수 있다.
- 따라서 비어있는 survivor 영역에 맨 앞부터 연속적으로 살아있는 객체를 저장하여(Compaction) survivor 영역의 공간을 효율적으로 사용하고, Fragmentation 문제를 방지하기 위함이다
- 정리하자면, Compaction을 이용해 Fragment 문제를 방지하고 Garbage Collection의 성능을 향상시키기 위해서이다

**GC의 기본 동작 방식**

1. **Stop the world(STP)**
    - GC를 실행하기 위해 JVM이 GC를 실행하는 스레드를 제외한 모든 스레드의 작업을 중단
    - GC가 종료되면 다시 중지된 스레드들이 작업을 실행함
    - 왜 일어날까?

2. *Mark and Sweep*
    - Mark : 사용되는 메모리와 사용되지 않는 메모리를 식별하는 작업
    - Sweep : Mark 단계에서 사용되지 않는 메모리로 식별된 메모리 할당 해제하는 작업

   STP 단계를 통해 GC 실행 스레드를 제외한 모든 스레드가 작업을 중단한 후

   GC가 스택의 모든 변수 또는 Reachable 객체를 스캔하면서 어떤 객체를 참조하고 있는지 탐색하고 사용되고 있는 메모리를 식별한다(Mark)

   그 후 Mark 되지 않은 객체들을 메모리에서 할당 해제한다(Sweep)


**GC 알고리즘 종류**

- **Serial GC**
    - 단일 스레드로 GC를 수행해  느리고,시간이 많이 소요(Stop The World가 다른 GC에 비해 길다)
    - Mark& Sweep& Compact 알고리즘 사용
    - WAS로 사용하는 JVM에서 Serial GC 사용하면 안되는 이유
        - 클라이언트용 장비에 최적화된 GC이기 때문에 WAS에서 이 방식을 사용하면 GC 속도가 매우 느려 웹 애플리케이션 속도가 엄청 느려짐
- **Parallel Young Generation Collectior**
    - young 영역의 GC를 멀티 스레드로 병렬 처리 → Serial GC보다 Stop The World 시간 짧음
    - Mark& Sweep& Compact 알고리즘 사용
- **Parallel Old Generation Collector**
    - young 영역, old 영역의 GC를 멀티스레드로 병렬 처리
    - mark - summary - compact 알고리즘 사용
- **Concurrent Mark & Sweep Collector(CMS)**
    - Heap 메모리의 크기가 클 때 사용
    - stop the world를 최대한 줄이기 위해 나온 알고리즘
    - 단편화가 발생할 수 있어 deprecated됨
        - 이유
            - 메모리를 한번에 회수하는 것이 아니라 여러 단계로 나누어 회수해서 메모리 영역에 여유 공간이 적어져서
- **G1(Garbage first)**
    - stop the world 시간이 가장 짧음
    - heap 메모리를 균등하게 region으로 나누고,각 region을 논리적으로 구분하여 객체를 할당

      (Eden region인지, Survivor region인지, Old region인지)

    - heap 영역 전체에 대해 gc를 하지 않고, region 단위로 탐색해서 garbage가 많은 region을 우선적으로 GC 진행

      compaction 과정도 heap 영역 전체를 대상으로 하지 않고, region 단위로 이루어져 GC에 소요되는 시간 단축
