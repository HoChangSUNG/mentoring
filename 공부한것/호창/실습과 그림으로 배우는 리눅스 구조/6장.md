# chapter6 메모리 계층

### **메모리 장치 계층 구조**

- 레지스터 : 사이즈가 제일 작고, 가격이 비싸고, 접근 속도 빠름
- 캐시 메모리
- 메모리
- 저장 장치 :  사이즈가 제일 크고, 가격이 싸고, 접근 속도 느림

### 캐시 메모리

- cpu가 캐시 메모리에 있는 데이터에만 접근할 경우 모든 접근이 캐시 메모리의 속도로 처리되므로 캐시 메모리가 없는 경우보다 빠르게 처리됨
- 사용 이유
    - cpu 내의 레지스터 안에서 계산하는 시간과 메모리에 접근하는 시간 사이의 차이를 메우기 위해 사용
    - cpu에서 명령을 처리하는 시간보다 메모리에 접근하여 데이터를 가져 오는 시간이 너무 느려 cpu가 아무리 빨리 명령을 처리하더라도 메모리에 접근하여 데이터를 가져오고, 메모리에 데이터를 쓰는 시간이 너무 길어 속도상 병목 지점이 되어버리기 때문
- **동작 방식**
    - 메모리를 조회할 때
        1. cpu의 레지스터의 메모리를 읽을 때, 캐시 라인 사이즈만큼 캐시 메모리로 읽어오고, 캐시 메모리에 저장된 내용을 cpu의 레지스터로 읽는다.
            
            ※ **캐시 라인 사이즈** : cpu가 정한  메모리에서 캐시 메모리로 읽어오는 크기
            
        2. 캐시 메모리에 있는 내용을 조회하려고 하면 메모리에 접근하지 않고 캐시 메모리에 접근하여 데이터를 읽는다.
            
            ![KakaoTalk_20230817_004004664](https://github.com/HoChangSUNG/mentoring/assets/76422685/6f30b54a-cbaa-469f-9f1d-2d2bb075a66b)

    
    - 메모리에 데이터를 쓸 때
        1. 레지스터에서 데이터를 변경하여 메모리에 쓰기 작업을 할 때, 변경된 데이터를 캐시 메모리에 저장하고, 캐시 라인에 메모리로부터 읽어들인 데이터가 변경되었다는 플래그(더티 플래그)를 표시하여 해당 캐시 라인을 더티(dirty)로 만든다
        2. 더티 플래그가 붙은 데이터는 write back(라이트 백) 방식을 이용해 메모리에 변경된 내용을 저장한다
            
            ※**write back** : 캐시 라인이 더티가 된 후 백그라운드에서 나중에 메모리에 변경 사항을 기록하는 방식
            
            ![KakaoTalk_20230817_004004664_01](https://github.com/HoChangSUNG/mentoring/assets/76422685/254519d4-8fcf-45f0-ba7c-4ef7ab3c9fb3)

            ![KakaoTalk_20230817_004004664_02](https://github.com/HoChangSUNG/mentoring/assets/76422685/b88aa16a-bc90-4fd7-89f8-99116834b8d5)

        
    - 캐시 메모리가 다 찬 경우
        1. 캐시 메모리에 존재하지 않는 데이터를 읽는 경우 기존의 캐시 메모리 중 1개를 파기
        2. 비어진 캐시 라인에 데이터를 읽어오고 캐시 라인의 데이터를 cpu의 레지스터에 전달
        3. **파기하는 캐시가 더티일 경우** 대응되는 메모리에 변경 내용을 덮어쓴 다음 캐시 라인을 버리는 동기화 작업 발생
            - 캐시 메모리가 가득 찬 상태에서 모든 캐시 라인이 더티라면 스래싱(thrashing)이 발생해 성능이 크게 감소될 수 있음
                - **스래싱** :  메모리 접근을 할 때마다 캐시 라인 안의 데이터가 자주 바뀌게 되는 것
        
- 계층형 캐시 메모리
    - 최근 x86_64 아키텍쳐의 cpu는 캐시 메모리가 계층형 구조로 구성됨
    - 각 계층은 사이즈, 레이턴시, 어느 논리 cpu 사이에 공유하는가 등이 다름
    - L1,L2,L3 등의 이름이 있고, CPU마다 어느 레벨의 캐시가 존재하는지 다름
    - L1 캐시가 가장 레지스터에 가깝고 용량이 적고 빠름, 번호가 늘수록 레지스터로부터 멀어지고 용량이 크고 속도가 느려

- **메모리 참조의 국소성**으로 인해 실제 시스템에서도 캐시 메모리가 이상적으로 동작
    - **메모리 참조의 국소성**
        - **시간 국소성**
            - 특정 시점에 접근하는 데이터는 가까운 미래에 다시 접근할 가능성이 크다
            - 예시로 루프 처리중인 코드 영역 등
        - **공간 국소성**
            - 특정 시점에 어떤 데이터에 접근하면 그 데이터와 가까운 주소에 있는 데이터를 접근할 확률이 높다
            - 예시로는 배열의 전체 검색 등
            

### Translation Lookaside Buffer

- **프로세스의 데이터 접근 과정 중 두 번째 과정에만 캐시 메모리가 적용**되어 고속화됨
- 프로세스의 데이터 접근 과정 중 첫 번째 과정의 속도를 높이기 위해  **Translation Lookaside Buffer 사용**
- **Translation Lookaside Buffer**
    - **가상 주소를 물리 주소로 변환(첫 번째 과정)하는 속도를 높이기 위해 사용하는 캐시**
- 프로세스 데이터 접근 과정
    1. 물리 메모리상에 존재하는 페이지 테이블을 참고하여 가상 주소를 물리 주소로 변환
    2. 1에서 구한 물리 주소를 이용해 물리 메모리에 접근

### 페이지 캐시

- 저장 장치 내의 파일을 커널의 메모리에 캐싱하는 것
- 페이지 단위로 저장 장치의 데이터를 캐싱
- 전체 프로세스에서 공유되는 자원이므로 페이지 캐시에 저장된 데이터를 읽어 들인 프로세스는 최초에 파일 데이터에 접근한 프로세스와 다른 프로세스여도 문제 없음
- 각 프로세스가 접근하는 파일의 데이터가 전부 페이지 캐시에 존재할 경우 파일의 접근 속도는 저장 장치의 접근 속도가 아닌 메모리 접근 속도에 근접하게 됨
- **동작 방식**
    - 저장 장치 데이터 조회 시
        
        ![KakaoTalk_20230817_004004664_03](https://github.com/HoChangSUNG/mentoring/assets/76422685/58a65f18-b2aa-4f48-b7d6-fa9ba7c874b7)

        1. 프로세스의 메모리에 파일의 데이터를 직접 복사하지 않고, 커널의 메모리 내의 페이지 캐시 영역에 복사한 후, 이 데이터를 메모리에 복사
        2. 페이지 캐시에 존재하는 데이터를 다시 읽으면 커널은 페이지 캐시의 데이터를 돌려줌
    - 프로세스가 데이터를 파일에 쓸 때
        1. 커널은 페이지 캐시에 데이터를 쓰면 더티 플래그를 붙여 해당 페이지를 더티 페이지로 만든다
            - 더티 플래그 : 데이터 쓸 때 해당되는 페이지에 대응하는 엔트리에 데이터 내용은 저장장치의 내용보다 새로운 것이라는 플래그
        2. 더티 페이지의 내용은 나중에 커널의 백그라운드로 저장 장치 파일에 더티 페이지의 내용을 반영(라이트 백), 더티 페이지 플래그를 지움
            
            ![KakaoTalk_20230817_004004664_04](https://github.com/HoChangSUNG/mentoring/assets/76422685/2e4257d3-8bd0-4f7f-b924-e937b24b9217)

            ![KakaoTalk_20230817_004004664_05](https://github.com/HoChangSUNG/mentoring/assets/76422685/5d021c97-2bff-4201-ac8b-8207c983ead7)

        
    - 시스템 메모리가 부족해질 경우
        1. 커널이 페이지 캐시를 해제
            1. 더티 페이지가 아닌 페이지를 파기
            2. 더티 페이지가 아닌 페이지를 파기해도 시스템 메모리가 부족하면 더티 페이지를 라이트 백 한 뒤 파기

### 버퍼 캐시( 7장에서 설명)

- 파일 시스템을 사용하지 않고 디바이스 파일을 이용하여 저장 장치에 직접 접근하는 등의 목적으로 사용
- 페이지 캐시와 버퍼 캐시를 합쳐 저장 장치 안의 데이터를 메모리에 넣어두는 방식

### 튜닝 파라미터

- 리눅스에는 페이지 캐시를 제어하기 위한 튜닝 파라미터들이 존재
- **sysctl의 `vm.dirty_writeback_centisecs`**
    - 더티 페이지의 라이트 백이 발생하는 주기 변경해주는 파라미터( 단위 : 1/100초)
    - 기본 값 :  5초에 1번
- **sysctl의 `vm.dirty_background_ratio`**
    - 시스템의 모든 물리 메모리 중 더티 페이지가 차지하는 최대 비율
    - 초과한 경우 백그라운드로 라이트 백 처리가 동작
    - 시스템의 메모리가 부족할 때 라이트 백 부하가 커지는 것을 방지
    - 기본 값 : 10
- **sysctl의 `vm.dirty_ratio`**
    - 더티 페이지가 차지하는 비율이 이 값(퍼센트)을 초과하면, 프로세스에 의한 파일에 쓰기의 연장으로 동기적인 라이트 백을 수행
    - 기본 값 : 20

### 페이지 캐시 정리

- 파일의 데이터가 페이지 캐시에 있으면 파일 접근이 굉장히 빨라진다.
- 설정을 변경했거나 시간이 지나면서 시스템 성능이 안좋아졌을 경우, 파일의 데이터가 페이지 캐시에 제대로 들어가는지 확인하는게 좋다.
- sysctl 파라미터들을 잘 튜닝하면 페이지 캐시의 라이트 백 I/O 부하를 예방할 수 있다.
- `sar -B`, `sar -d -p` 명령어를 통해 페이지 캐시에 관한 통계를 얻을 수 있다.

### **하이퍼 스레드(hyper-thread)**

- CPU의 계산은 굉장히 빠른 것에 비해, 메모리 및 캐시 메모리의 접근 레이턴시는 상대적으로 느리다. 따라서 CPU 사용 시간 중 대부분은 메모리나 캐시 메모리로부터 데이터를 기다리는 시간이다
    
    이러한 대기 시간 때문에 낭비되는 CPU의 자원을 하이퍼스레드 기능으로 유효하게 활용할 수 있음
    
- 하이퍼스레드 기능은 CPU 코어 1개의 레지스터 등 일부 자원을 2개씩(일반적) 구성하여 2개의 논리 CPU(하이퍼스레드라는 단위)로 인식되도록 하는 하드웨어의 기능
- CPU에 비해 2배 성능이 나오는 것은 아니고, 현실적으로 20~30%의 성능 향상이 나오면 훌륭한 것이라고 한다.
- 하이퍼스레드를 켰을 때 오히려 성능 저하가 발생하는 경우도 있기 때문에 성능 측정 이후에 사용해야 한다.
